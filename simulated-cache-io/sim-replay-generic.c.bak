#ifdef SIM_REPLAY
//retaining above SYNCIO ifdef just to differentiate from ASYNCIO code, remove 
// asyncio code later and these ifdefs can also go... FIXME

#include <stdio.h>
#include <unistd.h>
#include <stdlib.h>
#include <pthread.h>
#include <unistd.h>
#include <assert.h>
#include <time.h>
#include <sched.h>
#include <sys/time.h>
#include <fcntl.h>
#include <libaio.h>
#include <sys/prctl.h>
#include "vmbunching_structs.h"
#include "per-input-file.h"
#include "debugg.h"
#include "debug.h"
#include "pdd_config.h"
#include "replay-generic.h"
#ifndef TESTVMREPLAY	/* will be defined only in pdd_testvmreplay */
	#include "replay-plugins.h"	/* will be defined everywhere else */
	#include "sync-disk-interface.h"
#endif
#include "sectorcache.h"
#include "ioserveio.h"
#include "sync-replay-generic.h"
#include "ioruntime.h"
#include "fruntime.h"
#include "pruntime.h"

int cachesimflag = 0;
int writebackflag = 0;
int collectformat = 0;

unsigned long gtotalreadreq = 0;    /* # Read requests in trace */
unsigned long gtotalwritereq = 0;   /* # Write requests in trace */


/* Extern'ed from replay-plugins.c */
extern int preplayflag;
extern int freplayflag;
extern int sreplayflag;    /* default */
extern int ioreplayflag;

extern volatile int signal_done;    // Boolean: Signal'ed, need to quit
extern int disksimflag;
extern int runtimemap;

extern char *ibase;      // Input base name
extern char *ifile;
extern char *idir;        // Input directory base
extern char *idevnm;	//Input device name
extern int cpus_to_use;        // Number of CPUs to use
extern int def_iterations;      // Default number of iterations
extern int verbose;         // Boolean: Output some extra info
extern int write_enabled;       // Boolean: Enable writing
extern int read_enabled;       // Boolean: Enable reading
extern __u64 genesis;      // Earliest time seen
__u64 rgenesis;          // Our start time
size_t pgsize;           // System Page size
//LIST_HEAD(input_devs);       // List of devices to handle
//LIST_HEAD(input_files);      // List of input files to handle
//LIST_HEAD(map_devs);     // List of device maps
extern int no_stalls;       // Boolean: default disabled stalls
extern int speedupfactor;	//Default: no speedup
extern int find_records;        // Boolean: Find record files auto
extern long total_submitted;
extern __u64 disk_hits;
extern __u64 disk_hits_r;
extern __u64 disk_hits_w;

extern int naios;         // Number of AIOs per thread
extern int syncfd;
extern int verbose;
extern FILE * ftimeptr;
inline __u64 gettime(void);

#ifndef TESTVMREPLAY	/* will be defined only in pdd_testvmreplay */
	void iocbs_map(struct thr_info *tip, struct iocb **list,
                         struct io_pkt *pkts, int ntodo);
#else
	void iocbs_map(struct thr_info *tip, struct iocb **list,
                         struct vm_pkt *pkts, int ntodo);
#endif

void reset_input_file(struct thr_info *tip);
int nfree_current(struct thr_info *tip);

void sim_replay(struct thr_info *tip, 
                        struct io_pkt *pkts, int ntodo)
{
    int i;              
    struct io_pkt *pkt; 
#if defined (PDDREPLAY_DEBUG_SS) || defined(TESTVMREPLAY_DEBUG) || defined(SIMREPLAY_DEBUG_SS_DONE)   
    fprintf(stdout, "In %s\n", __FUNCTION__);
    assert(pkts != NULL);
    assert(0 < ntodo);
#endif 
                
    pthread_mutex_lock(&tip->mutex);
    for (i = 0, pkt = pkts; i < ntodo; i++, pkt++) {
        assert(pkt != NULL);
        __u32 rw = pkt->rw;

        if (verbose > 1)
        {
            fprintf(stdout, "\t%10u + %10lu %c%c\n",
                pkt->ioblk,
                (unsigned long)(pkt->nbytes >> 12),
                rw ? 'R' : 'W',
                (rw == 1 && pkt->rw == 0) ? '!' : ' ');
            fprintf(tip->vfp, "\t%10u + %10lu %c%c\n",
                pkt->ioblk,
                (unsigned long)pkt->nbytes >> 12,
                rw ? 'R' : 'W',
                (rw == 1 && pkt->rw == 0) ? '!' : ' ');
        }

		/* Dont do actual disk read, we will just simulate it */
		/* pkt->content should already contain the hash for the block
		 * that was read/written here.
		 */
		continue;
	}
	pthread_mutex_unlock(&tip->mutex);
}


#ifndef TESTVMREPLAY	/* will be defined only in pdd_testvmreplay */
/** map_n_process_bunch - Process a bunch of requests after mapping first
 * @tip: Per-thread information
 * @bunch: Bunch to map and process
 */
void sim_map_n_process_bunch(struct thr_info *tip, struct vm_bunch *bunch)
{
	__u64 vmp_iter=0;
	struct io_pkt *iopl = NULL;
	struct preq_spec *preql = NULL;
	int tot_pkts = 0;

#if defined(DEBUG_SS) || defined (PDDREPLAY_DEBUG_SS) || defined(SIMREPLAY_DEBUG_SS_DONE)
    fprintf(stdout, "In %s\n", __FUNCTION__);
    assert(0 < bunch->hdr.npkts && bunch->hdr.npkts <= MAP_BT_MAX_PKTS);
#endif 

	if (!no_stalls)
	{
#ifdef REPLAYDIRECT_TEST
		unsigned long long amt = 18446744073709528226ULL;			
		printf("try stalling %llu\n", amt);
		stall(tip, amt);
#else		
		printf("try stalling %llu\n", bunch->hdr.time_stamp - genesis);
		stall(tip, bunch->hdr.time_stamp - genesis);
#endif
	}
	else
		usleep(1000);

	//while (!is_send_done(tip) && (vmp_iter < bunch->hdr.npkts)) 
	while ((vmp_iter < bunch->hdr.npkts)) 
	{
#if defined(SIMREPLAY_DEBUG_SS_DONE)
		fprintf(stdout, "%s for vmp_iter=%llu\n", __FUNCTION__, vmp_iter);
#endif
		int num_vop = 0, vop_iter = 0;
		int ntodo = 0, num_disk = 0;	
		unsigned long long stime=0, etime=0;
#ifdef REPLAYDIRECT_TEST
		int i = 0;
		struct vm_pkt *pkt;
#endif

#if defined(SIMREPLAY_DEBUG_SS_DONE)
		if (bunch->pkts[vmp_iter].rw)	/* Read request */
			fprintf(stdout, "----------- READ REQUEST --------------\n");
		else
			fprintf(stdout, "----------- WRITE REQUEST -------------\n");
#endif
		if (bunch->pkts[vmp_iter].rw)	/* Read request */
			gtotalreadreq++;
		else
			gtotalwritereq++;
		if (((gtotalreadreq+gtotalwritereq)) % 10000 == 0)
		{
			fprintf(stderr, ".");
			fflush(stdout);
		}
		stime = gettime();

		/* Before sector-based base-cache, PROVIDED & CONFIDED perform
		 * deduplication metadata lookup, whereas IODEDUP just follows STANDARD!
		 */
		if (preplayflag)
			num_vop = preplay_map(tip, &preql, &bunch->pkts[vmp_iter]); //PROVIDED
		else if (freplayflag)
			num_vop = freplay_map(tip, &preql, &bunch->pkts[vmp_iter]); //CONFIDED
		else if (sreplayflag)
			num_vop = sreplay_map(tip, &preql, &bunch->pkts[vmp_iter]); //STANDARD
		else if (ioreplayflag)
			num_vop = sreplay_map(tip, &preql, &bunch->pkts[vmp_iter]); //STANDARD

#ifdef REPLAYDIRECT_TEST
		pkt = &bunch->pkts[vmp_iter];
		fprintf(stdout, "vblk=%u: pblk=[", pkt->block);
	    for (i = 0; i < num_vop; i++) 
		{	
			fprintf(stdout, "(%u,%u,%u) ", preql[i].start, preql[i].ioblk,
									preql[i].end);
		}
		fprintf(stdout, "]\n");
#endif	
		if (num_vop == 0 && ((bunch->pkts[vmp_iter].rw && !read_enabled) || 
			(!bunch->pkts[vmp_iter].rw && !write_enabled)))
		{
			/* If read request but read_enabled==0, then num_vop = 0
			 * If write request but write_enabled==0, then num_vop = 0
			 * In both above cases, it is not error, just continue w/o count
			 */
#if defined(DEBUG_SS) || defined (PDDREPLAY_DEBUG_SS) || defined(SIMREPLAY_DEBUG_SS_DONE)
			fprintf(stderr, "Error in above map function or !write_enabled\n");
#endif
			if (!bunch->pkts[vmp_iter].rw)				
				free(bunch->pkts[vmp_iter].content); //malloc in get_vmbunch()
/*
			etime = gettime();
			fprintf(ftimeptr, "%llu z%d %d rw(%d)\n", etime - stime, num_vop,
								bunch->pkts[vmp_iter].nbytes/BLKSIZE,
								bunch->pkts[vmp_iter].rw);
*/
			total_submitted++;
			vmp_iter++;
			continue;
		}
		else if (num_vop == 0)
			fatal(NULL, ERR_USERCALL, "Error in above map function");

		if (writebackflag && !(bunch->pkts[vmp_iter].rw))
		{
			/* If we are in writeback mode, and this is a write request, 
			 * the buck stops here. Note the "write response time" only till 
			 * here. The rest of it is off-band and does not contribute to 
			 * user-perceived write response time.
			 */
			etime = gettime();
			fprintf(ftimeptr, "%llu z%d %d rw(%d)\n", etime - stime, num_vop,
                                bunch->pkts[vmp_iter].nbytes/BLKSIZE,
								bunch->pkts[vmp_iter].rw);
		}

		/* In cache simulation mode, i.e. -c option, we assume that the requests
		 * are being intercepted at a layer above the page cache, whereas in
		 * the non-cache simulation mode, we assume that the page cache is
		 * the underlying cache of this system itself, and hence an actual
		 * disk replay would auto look it up, i.e. no simulation of cache
		 */
		if (cachesimflag)
		{
			/* Look-up base-cache in cache simulation mode */
			if (bunch->pkts[vmp_iter].rw)	/* Read request */
			{
				/* Look-up for each blk (for given request) into base-cache.
				 * If the lookup succeeds, the "done" should be set for 
				 * those blks and only the remaining need to be 
				 * "fetched from disk". 
				 */
				int rc = 0;
				rc = find_in_sectorcache(&preql, num_vop);
				if (rc < 0)
	                fatal(NULL, ERR_USERCALL, "Error in sectorcache_lookup\n");
			}
			else	/* Write request */
			{
				/* update the base-cache with new value */
				/* if a new block is being written, corresponding block 
				 * buffer will not be present in base-cache, hence may 
				 * result in some eviction, else it will just be an update 
				 * in cache (assume write-back cache)
				 */
				int rc = 0;
				rc = overwrite_in_sectorcache(&preql, num_vop);
                if (rc < 0)
                    fatal(NULL, ERR_USERCALL, "Error in overwrite_in_sectorcache\n");
			}
		}

		if (ioreplayflag)
		{
			/* The content-based cache simulated by default, so no special flag
			 * in this case. Change this later if needed FIXME. */
			int rc = 0;
			if (!bunch->pkts[vmp_iter].rw && mappingTrimScanIO(&preql, num_vop))
				fatal(NULL, ERR_USERCALL, "Error in mappingTrimScanIO\n");
			rc = ioreplay_map(&preql, num_vop);
			if (rc < 0)
				fatal(NULL, ERR_USERCALL, "Error in ioreplay_map\n");
		}

		/* Accessing disk for read/write requests */
	    num_disk = preql_map(&preql, &iopl, num_vop);
		if (num_disk < 0)
			fatal(NULL, ERR_USERCALL, "Error in preql_map\n");
#if defined(DEBUG_SS) || defined (PDD_REPLAY_DEBUG_SS_DONE)
		if (!cachesimflag)
			assert(num_disk == num_vop);
		else
			assert(num_disk <= num_vop);
		fprintf(stdout, "num_vop = %d, vop_iter =%d, vmp_iter =%llu\n",
						num_vop, vop_iter, vmp_iter);
#endif
		ntodo = num_vop - vop_iter;
       	assert(0 < ntodo);

		/* If we use collect.ko formatted traces, it contains the MD5hash
		 * of the read content as well, hence we need not read the disk in real
		 * However, if we use pdatadump traces, we need recreated disk and read.
		 */
		if (disksimflag && num_disk)
			sim_replay(tip, iopl+vop_iter, ntodo);
		else if (num_disk)
			sync_replay(tip, iopl+vop_iter, ntodo);
#if defined(DEBUG_SS) || defined (PDDREPLAY_DEBUG_SS)
		fprintf(stdout, "sync_map_n_process_bunch:total_submitted = %ld\n", total_submitted);
#endif
		tot_pkts += ntodo;
		vop_iter += ntodo;

		/* ARC-cache update to be done in ioread_mapupdate().
		 * In case, we are building mapping at runtime, then the disk blocks
		 * that have been read from disk need to be deduplicated and mapping 
		 * updated. So for all read requests with done==0, update their
		 * mapping in the deduplication metadata. This would not be needed if
		 * apriori mapping were used via scanning.
		 * Similarly, do metadata updates for CONFIDED/PROVIDED.
		 * Also, if we are simulating cache, then add content to cache if needed.
		 */
		if (bunch->pkts[vmp_iter].rw && runtimemap)	/* Read request */
		{
			int rc = 0;
			if (ioreplayflag)
				rc = ioread_mapupdate(&preql, num_vop);		//IODEDUP
			else if (freplayflag) 							//CONFIDED
				rc = fread_mapupdate(&preql, &bunch->pkts[vmp_iter], num_vop);
			else if (preplayflag)							//PROVIDED
				rc = pread_mapupdate(&preql, &bunch->pkts[vmp_iter], num_vop);		
			if (rc < 0)
				fatal(NULL, ERR_USERCALL, "Error in above mapupdate\n");
		}

		/* For all read blocks that were "fetched from disk" or from content cache
		*  i.e. bcachefound = 0
		 * perform cache add for the new content. 
		 * Performing deduplication and updating metadata for runtimemap
		 * was already done above.
		 */
		if (cachesimflag)
		{
			/* Look-up base-cache in cache simulation mode */
			if (bunch->pkts[vmp_iter].rw)	/* Read request */
			{
				/* update the base-cache with new value */
				/* if a new block is being added, corresponding block buffer will 
				 * not be present in base-cache, hence may result in some eviction,
				 */
				int rc = 0;
				rc = overwrite_in_sectorcache(&preql, num_vop);
                if (rc < 0)
                    fatal(NULL, ERR_USERCALL, "Error in overwrite_in_sectorcache\n");
			}
		}

        /* If we are NOT in writeback mode, or this is a READ request, 
         * note the "response time" all the way till here because for all
		 * read requests and for all write-through cache write requests, 
		 * this does contribute to user-perceived response time.
         */
        if (!writebackflag || bunch->pkts[vmp_iter].rw)
        {
            etime = gettime();
            fprintf(ftimeptr, "%llu z%d %d rw(%d)\n", etime - stime, num_vop,
                                bunch->pkts[vmp_iter].nbytes/BLKSIZE,
                                bunch->pkts[vmp_iter].rw);
        }

#ifdef PRO_STATS
		total_submitted++;
		if ((total_submitted & 0x1FFF) == 0)
		{
			fprintf(stdout, ".");	//to show progress after 131072 entries
			fflush(stdout);
		}
#endif
		if (bunch->pkts[vmp_iter].content)				
			free(bunch->pkts[vmp_iter].content); //malloc in get_vmbunch()
		if (preql)
		{
			for (vop_iter=0; vop_iter<num_vop; vop_iter++)
				free((preql+(vop_iter))->content);
			free(preql);	preql = NULL;	/* Work over, free it */
		}
		if (iopl)
		{
			for (vop_iter=0; vop_iter<num_disk; vop_iter++)
				free((iopl+(vop_iter))->content);
			free(iopl);	iopl = NULL;	/* Work over, free it */
		}

		vmp_iter++;
	}
}
#else	/* will be true only in testvmreplay */
/**
 * process_bunch - Process a bunch of requests
 * @tip: Per-thread information
 * @bunch: Bunch to process
 */
//FIXME: this is incomplete ==== it is async version still, not sync
void sync_process_bunch(struct thr_info *tip, struct vm_bunch *bunch)
{
    __u32 i = 0;
    struct iocb *list[bunch->hdr.npkts];
    fprintf(stdout, "In %s: this is incomplete ==== it is async version still, not sync\n", __FUNCTION__);

#if defined(TESTVMREPLAY_DEBUG)
    fprintf(stdout, "In %s\n", __FUNCTION__);
#endif
    assert(0 < bunch->hdr.npkts && bunch->hdr.npkts <= BT_MAX_PKTS);
    while (!is_send_done(tip) && (i < bunch->hdr.npkts)) {
#if defined(TESTVMREPLAY_DEBUG)
    	fprintf(stdout, "In while loop in %s\n", __FUNCTION__);
#endif
        long ndone;
        int ntodo = min(nfree_current(tip), bunch->hdr.npkts - i);

        assert(0 < ntodo && ntodo <= naios);
        iocbs_map(tip, list, &bunch->pkts[i], ntodo);
        if (!no_stalls)
            stall(tip, bunch->hdr.time_stamp - genesis);
		else
			usleep(1000*10);

        if (ntodo) {
            if (verbose > 1)
            {
                fprintf(stdout, "submit(%d)\n", ntodo);
                fprintf(tip->vfp, "submit(%d)\n", ntodo);
            }
            ndone = io_submit(tip->ctx, ntodo, list);
            if (ndone != (long)ntodo) {
                fatal("io_submit", ERR_SYSCALL,
                    "io_submit(%d:%ld) failed (%s)\n",
                    ntodo, ndone,
                    strerror(labs(ndone)));
                /*NOTREACHED*/
            }

            pthread_mutex_lock(&tip->mutex);
            tip->naios_out += ndone;
            assert(tip->naios_out <= naios);
            if (tip->reap_wait) {
                tip->reap_wait = 0;
                pthread_cond_signal(&tip->cond);
            }
            pthread_mutex_unlock(&tip->mutex);

            i += ndone;
#ifdef PRO_STATS
			total_submitted += ndone;
			fprintf(stdout, "xxxtal_submitted = %ld\n", total_submitted);
#endif
            assert(i <= bunch->hdr.npkts);
        }
    }
}
#endif	/* process_bunch only present in testvmreplay */

/**
 * replay_sub - Worker thread to submit AIOs that are being replayed
 */
void *sim_replay_sub(void *arg)
{
    char path[MAXPATHLEN];
	struct vm_bunch *bunch = calloc(1, sizeof(struct vm_bunch));

    struct thr_info *tip = arg;
#if defined (PDDREPLAY_DEBUG_SS) || defined(SIMREPLAY_DEBUG_SS_DONE)
	fprintf(stdout, "In %s\n", __FUNCTION__);
#endif

	if (!disksimflag)
	{
	    sprintf(path, "/dev/%s", idevnm);
		tip->ofd = open_sync_device((char*)path);
#if defined(TESTVMREPLAY_DEBUG) || defined (PDDREPLAY_DEBUG_SS)  || defined(SIMREPLAY_DEBUG_SS)
		fprintf(stdout, "Device is %s\n", path);
#endif
	}

    //pin_to_cpu(tip);
	prctl(PR_SET_NAME,"simreplay",0,0,0);
    set_replay_ready();
#if defined(SIMREPLAY_DEBUG_SS)
	fprintf(stdout, "is_send_done(tip)=%d, iterations=%d\n", 
					is_send_done(tip), tip->iterations);
#endif
    while (tip->iterations--) {
        wait_iter_start();
        if (verbose > 1)
		{
            fprintf(stdout, "\n=== %d ===\n", tip->iterations);
            fprintf(tip->vfp, "\n=== %d ===\n", tip->iterations);
		}
        while (!is_send_done(tip) && next_bunch(tip, bunch))
		{
#ifndef TESTVMREPLAY	/* will be defined only in pdd_testvmreplay */
            sim_map_n_process_bunch(tip, bunch);
#else
			sync_process_bunch(tip, bunch);
#endif
		}
        set_iter_done();
        reset_input_file(tip);
    }
	fprintf(stdout, "outside while loop\n");
    tip->send_done = 1;
    set_replay_done();
#ifdef PRO_STATS
	fprintf(stdout, "sync_replay_sub:total_submitted = %ld\n", total_submitted);
#endif

	if (!disksimflag)
		close(tip->ofd);	
	free(bunch);
    return NULL;
}

#endif /* SYNCIO */
